"""
Run this script to recreate the original onnx model.
Example usage:
python my_model.py out_model_path.onnx
"""

from onnx import helper, numpy_helper, TensorProto

import onnx
import numpy as np
import sys
import os

DATA_DIR = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'my_model')

def clear_field(proto, field):
    proto.ClearField(field)
    return proto

def order_repeated_field(repeated_proto, key_name, order):
    order = list(order)
    repeated_proto.sort(key=lambda x: order.index(getattr(x, key_name)))

def make_node(op_type, inputs, outputs, name=None, doc_string=None, domain=None, **kwargs):
    node = helper.make_node(op_type, inputs, outputs, name, doc_string, domain, **kwargs)
    if doc_string == '':
        node.doc_string = ''
    order_repeated_field(node.attribute, 'name', kwargs.keys())
    return node

def make_graph(*args, doc_string=None, **kwargs):
    graph = helper.make_graph(*args, doc_string=doc_string, **kwargs)
    if doc_string == '':
        graph.doc_string = ''
    return graph

model = helper.make_model(
    opset_imports=[
        clear_field(helper.make_operatorsetid('', 12), 'domain'),
        helper.make_operatorsetid('com.microsoft', 1),
        helper.make_operatorsetid('com.microsoft.mlfeaturizers', 1),
        helper.make_operatorsetid('com.microsoft.nchwc', 1),
        helper.make_operatorsetid('ai.onnx.training', 1),
        helper.make_operatorsetid('ai.onnx.preview.training', 1),
        helper.make_operatorsetid('com.microsoft.experimental', 1),
        helper.make_operatorsetid('ai.onnx.ml', 2),
    ],
    ir_version=6,
    producer_name='pytorch',
    producer_version='1.9',
    graph=make_graph(
        name='torch-jit-export',
        inputs=[
            helper.make_tensor_value_info('input_ids', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('attention_mask', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('global_attention_mask', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('token_type_ids', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('sen_lens', TensorProto.INT64, shape=['batch', 'seq_len']),
        ],
        outputs=[helper.make_tensor_value_info('output', TensorProto.FLOAT, shape=[1, 255, 1]), helper.make_tensor_value_info('663', TensorProto.FLOAT, shape=['Softmax663_dim_0', 5])],
        initializer=[
            numpy_helper.from_array(np.array([-0.974609375], dtype='float16'), name='qna_outputs_hiddensize_1.projection.bias'),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const0_MiddleLayer_2hiddensize_hiddensize.projection.bias.npy')).astype('float16').reshape([768]),
                name='MiddleLayer_2hiddensize_hiddensize.projection.bias',
            ),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const1_ranking_outputs_onedcg.projection.weight.npy')).astype('float16').reshape([5, 768]), name='ranking_outputs_onedcg.projection.weight'),
            numpy_helper.from_array(np.array([-0.03851318359375, -0.0614013671875, -0.055572509765625, -0.06756591796875, -0.06451416015625], dtype='float16'), name='ranking_outputs_onedcg.projection.bias'),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const2_sentence_wise_att.layer.0.attention.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.0.attention.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const3_sentence_wise_att.layer.0.attention.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.0.attention.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const4_sentence_wise_att.layer.0.attention.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.0.attention.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const5_sentence_wise_att.layer.0.intermediate.dense.bias.npy')).astype('float16').reshape([3072]),
                name='sentence_wise_att.layer.0.intermediate.dense.bias',
            ),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const6_sentence_wise_att.layer.0.output.dense.bias.npy')).astype('float16').reshape([768]), name='sentence_wise_att.layer.0.output.dense.bias'),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const7_sentence_wise_att.layer.0.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.0.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const8_sentence_wise_att.layer.0.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.0.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const9_sentence_wise_att.layer.1.attention.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.1.attention.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const10_sentence_wise_att.layer.1.attention.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.1.attention.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const11_sentence_wise_att.layer.1.attention.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.1.attention.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const12_sentence_wise_att.layer.1.intermediate.dense.bias.npy')).astype('float16').reshape([3072]),
                name='sentence_wise_att.layer.1.intermediate.dense.bias',
            ),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const13_sentence_wise_att.layer.1.output.dense.bias.npy')).astype('float16').reshape([768]), name='sentence_wise_att.layer.1.output.dense.bias'),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const14_sentence_wise_att.layer.1.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.1.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const15_sentence_wise_att.layer.1.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='sentence_wise_att.layer.1.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const16_longformer.embeddings.word_embeddings.weight.npy')).astype('float16').reshape([50265, 768]),
                name='longformer.embeddings.word_embeddings.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const17_longformer.embeddings.position_embeddings.weight.npy')).astype('float16').reshape([4098, 768]),
                name='longformer.embeddings.position_embeddings.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const18_longformer.embeddings.token_type_embeddings.weight.npy')).astype('float16').reshape([4096, 768]),
                name='longformer.embeddings.token_type_embeddings.weight',
            ),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const19_longformer.embeddings.LayerNorm.weight.npy')).astype('float16').reshape([768]), name='longformer.embeddings.LayerNorm.weight'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const20_longformer.embeddings.LayerNorm.bias.npy')).astype('float16').reshape([768]), name='longformer.embeddings.LayerNorm.bias'),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const21_longformer.encoder.layer.0.attention.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.0.attention.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const22_longformer.encoder.layer.0.attention.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.0.attention.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const23_longformer.encoder.layer.0.attention.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.0.attention.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const24_longformer.encoder.layer.0.intermediate.dense.bias.npy')).astype('float16').reshape([3072]),
                name='longformer.encoder.layer.0.intermediate.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const25_longformer.encoder.layer.0.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.0.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const26_longformer.encoder.layer.0.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.0.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const27_longformer.encoder.layer.0.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.0.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const28_longformer.encoder.layer.1.attention.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.1.attention.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const29_longformer.encoder.layer.1.attention.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.1.attention.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const30_longformer.encoder.layer.1.attention.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.1.attention.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const31_longformer.encoder.layer.1.intermediate.dense.bias.npy')).astype('float16').reshape([3072]),
                name='longformer.encoder.layer.1.intermediate.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const32_longformer.encoder.layer.1.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.1.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const33_longformer.encoder.layer.1.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.1.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const34_longformer.encoder.layer.1.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.1.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const35_longformer.encoder.layer.2.attention.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.2.attention.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const36_longformer.encoder.layer.2.attention.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.2.attention.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const37_longformer.encoder.layer.2.attention.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.2.attention.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const38_longformer.encoder.layer.2.intermediate.dense.bias.npy')).astype('float16').reshape([3072]),
                name='longformer.encoder.layer.2.intermediate.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const39_longformer.encoder.layer.2.output.dense.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.2.output.dense.bias',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const40_longformer.encoder.layer.2.output.LayerNorm.weight.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.2.output.LayerNorm.weight',
            ),
            numpy_helper.from_array(
                np.load(os.path.join(DATA_DIR, 'const41_longformer.encoder.layer.2.output.LayerNorm.bias.npy')).astype('float16').reshape([768]),
                name='longformer.encoder.layer.2.output.LayerNorm.bias',
            ),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const42_671.npy')).astype('float16').reshape([768, 2304]), name='671'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const43_676.npy')).astype('float16').reshape([2304]), name='676'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const44_684.npy')).astype('float16').reshape([768, 2304]), name='684'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const45_689.npy')).astype('float16').reshape([2304]), name='689'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const46_690.npy')).astype('float16').reshape([768, 768]), name='690'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const47_691.npy')).astype('float16').reshape([768, 3072]), name='691'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const48_692.npy')).astype('float16').reshape([3072, 768]), name='692'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const49_700.npy')).astype('float16').reshape([768, 2304]), name='700'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const50_705.npy')).astype('float16').reshape([2304]), name='705'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const51_713.npy')).astype('float16').reshape([768, 2304]), name='713'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const52_718.npy')).astype('float16').reshape([2304]), name='718'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const53_719.npy')).astype('float16').reshape([768, 768]), name='719'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const54_720.npy')).astype('float16').reshape([768, 3072]), name='720'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const55_721.npy')).astype('float16').reshape([3072, 768]), name='721'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const56_729.npy')).astype('float16').reshape([768, 2304]), name='729'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const57_734.npy')).astype('float16').reshape([2304]), name='734'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const58_742.npy')).astype('float16').reshape([768, 2304]), name='742'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const59_747.npy')).astype('float16').reshape([2304]), name='747'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const60_748.npy')).astype('float16').reshape([768, 768]), name='748'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const61_749.npy')).astype('float16').reshape([768, 3072]), name='749'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const62_750.npy')).astype('float16').reshape([3072, 768]), name='750'),
            numpy_helper.from_array(np.array(1.0, dtype='float16'), name='657'),
            numpy_helper.from_array(np.array(-10000.0, dtype='float16'), name='655'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='753'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='754'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const63_755.npy')).astype('float16').reshape([1536, 768]), name='755'),
            numpy_helper.from_array(np.array([-1], dtype='int64'), name='756'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const64_764.npy')).astype('float16').reshape([768, 2304]), name='764'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const65_769.npy')).astype('float16').reshape([2304]), name='769'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const66_770.npy')).astype('float16').reshape([768, 768]), name='770'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const67_771.npy')).astype('float16').reshape([768, 3072]), name='771'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const68_772.npy')).astype('float16').reshape([3072, 768]), name='772'),
            numpy_helper.from_array(np.array([-1], dtype='int64'), name='773'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const69_781.npy')).astype('float16').reshape([768, 2304]), name='781'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const70_786.npy')).astype('float16').reshape([2304]), name='786'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const71_787.npy')).astype('float16').reshape([768, 768]), name='787'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const72_788.npy')).astype('float16').reshape([768, 3072]), name='788'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const73_789.npy')).astype('float16').reshape([3072, 768]), name='789'),
            numpy_helper.from_array(np.load(os.path.join(DATA_DIR, 'const74_790.npy')).astype('float16').reshape([768, 1]), name='790'),
            numpy_helper.from_array(np.array(1, dtype='int64'), name='137'),
            numpy_helper.from_array(np.array(1.0, dtype='float16'), name='143'),
            numpy_helper.from_array(np.array(-10000.0, dtype='float16'), name='145'),
            numpy_helper.from_array(np.array(1, dtype='int64'), name='147'),
            numpy_helper.from_array(np.array(1, dtype='int32'), name='151'),
            numpy_helper.from_array(np.array(1, dtype='int64'), name='155'),
            numpy_helper.from_array(np.array(0, dtype='int64'), name='428'),
            numpy_helper.from_array(np.array([], dtype='float16'), name='426'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='176'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='179'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='182'),
            numpy_helper.from_array(np.array([1, 1, 1], dtype='int64'), name='486'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='462'),
            numpy_helper.from_array(np.array(0, dtype='int64'), name='588'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='464'),
            numpy_helper.from_array(np.array(0, dtype='int64'), name='578'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='459'),
            numpy_helper.from_array(np.array(1, dtype='int64'), name='473'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='258'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='261'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='264'),
            numpy_helper.from_array(np.array(-10000.0, dtype='float16'), name='500'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='465'),
            numpy_helper.from_array(np.array(10000, dtype='int32'), name='585'),
            numpy_helper.from_array(np.array(1, dtype='int32'), name='591'),
            numpy_helper.from_array(np.array(1, dtype='int32'), name='517'),
            numpy_helper.from_array(np.array(0, dtype='int64'), name='469'),
            numpy_helper.from_array(np.array(0, dtype='int64'), name='504'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='340'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='343'),
            numpy_helper.from_array(np.array(0.0, dtype='float16'), name='346'),
            numpy_helper.from_array(np.array(10000, dtype='int32'), name='511'),
            numpy_helper.from_array(np.array(0, dtype='int64'), name='514'),
            numpy_helper.from_array(np.array([9223372036854775807], dtype='int64'), name='466'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='467'),
            numpy_helper.from_array(np.array([9223372036854775807], dtype='int64'), name='461'),
            numpy_helper.from_array(np.array(1.0, dtype='float16'), name='498'),
            numpy_helper.from_array(np.array([1], dtype='int64'), name='460'),
            numpy_helper.from_array(np.array(0, dtype='int64'), name='420'),
            numpy_helper.from_array(np.array(True, dtype='bool'), name='424'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='162_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.embeddings.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.embeddings.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='173_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='671_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='676_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='684_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='689_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='214_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='690_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='216_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.0.attention.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='217_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='218_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.0.attention.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.0.attention.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='229_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='691_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='231_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.0.intermediate.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='240_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='692_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='242_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.0.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='243_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='244_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.0.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.0.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='255_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='700_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='705_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='713_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='718_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='296_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='719_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='298_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.1.attention.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='299_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='300_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.1.attention.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.1.attention.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='311_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='720_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='313_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.1.intermediate.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='322_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='721_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='324_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.1.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='325_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='326_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.1.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.1.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='337_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='729_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='734_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='742_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='747_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='378_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='748_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='380_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.2.attention.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='381_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='382_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.2.attention.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.2.attention.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='393_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='749_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='395_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.2.intermediate.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='404_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='750_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='406_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.2.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='407_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='408_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.2.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='longformer.encoder.layer.2.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='419_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='489_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='755_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='491_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='MiddleLayer_2hiddensize_hiddensize.projection.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='492_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='764_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='769_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='534_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='770_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='536_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.0.attention.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='537_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='538_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.0.attention.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.0.attention.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='549_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='771_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='551_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.0.intermediate.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='552_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='560_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='772_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='562_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.0.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='563_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='564_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.0.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.0.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='575_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='781_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='786_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='608_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='787_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='610_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.1.attention.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='611_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='612_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.1.attention.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.1.attention.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='623_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='788_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='625_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.1.intermediate.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='626_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='634_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='789_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='636_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.1.output.dense.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='637_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='638_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.1.output.LayerNorm.weight_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='sentence_wise_att.layer.1.output.LayerNorm.bias_scale'),
            numpy_helper.from_array(np.array(0.007874015718698502, dtype='float32'), name='649_scale'),
        ],
        doc_string='',
        value_info=[
            helper.make_tensor_value_info('148', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('149', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('150', TensorProto.INT32, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('152', TensorProto.INT32, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('153', TensorProto.INT32, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('154', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('156', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('159', TensorProto.FLOAT16, shape=['batch', 'max_seq_len', 768]),
            helper.make_tensor_value_info('158', TensorProto.FLOAT16, shape=['batch', 'max_seq_len', 768]),
            helper.make_tensor_value_info('161', TensorProto.FLOAT16, shape=['batch', 'max_seq_len', 768]),
            helper.make_tensor_value_info('160', TensorProto.FLOAT16, shape=['batch', 'max_seq_len', 768]),
            helper.make_tensor_value_info('162', TensorProto.FLOAT16, shape=['batch', 'max_seq_len', 768]),
            helper.make_tensor_value_info('138', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('139', TensorProto.INT64, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('140', TensorProto.INT64, shape=['batch', 1, 'max_seq_len']),
            helper.make_tensor_value_info('141', TensorProto.INT64, shape=['batch', 1, 1, 'max_seq_len']),
            helper.make_tensor_value_info('142', TensorProto.FLOAT16, shape=['batch', 1, 1, 'max_seq_len']),
            helper.make_tensor_value_info('144', TensorProto.FLOAT16, shape=['batch', 1, 1, 'max_seq_len']),
            helper.make_tensor_value_info('146', TensorProto.FLOAT16, shape=['batch', 1, 1, 'max_seq_len']),
            helper.make_tensor_value_info('338', TensorProto.FLOAT16, shape=['batch', 1, 'max_seq_len']),
            helper.make_tensor_value_info('339', TensorProto.FLOAT16, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('180', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('183', TensorProto.FLOAT16, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('177', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('178', TensorProto.INT32, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('217', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('218', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('243', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('244', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('262', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('265', TensorProto.FLOAT16, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('259', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('260', TensorProto.INT32, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('299', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('300', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('325', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('326', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('344', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('347', TensorProto.FLOAT16, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('341', TensorProto.BOOL, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('342', TensorProto.INT32, shape=['batch', 'max_seq_len']),
            helper.make_tensor_value_info('381', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('382', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('407', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('408', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('427', TensorProto.INT64, shape=[2]),
            helper.make_tensor_value_info('429', TensorProto.INT64, shape=[]),
            helper.make_tensor_value_info('430', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('458', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('463', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('658', TensorProto.BOOL, shape=None),
            helper.make_tensor_value_info('472', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('474', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('478', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('484', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('492', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('503', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('505', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('507', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('509', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('494', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('495', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('496', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('499', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('501', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('502', TensorProto.INT32, shape=None),
            helper.make_tensor_value_info('510', TensorProto.INT32, shape=None),
            helper.make_tensor_value_info('512', TensorProto.INT32, shape=None),
            helper.make_tensor_value_info('513', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('515', TensorProto.BOOL, shape=None),
            helper.make_tensor_value_info('518', TensorProto.INT32, shape=None),
            helper.make_tensor_value_info('537', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('538', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('552', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('563', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('564', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('577', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('579', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('581', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('583', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('584', TensorProto.INT32, shape=None),
            helper.make_tensor_value_info('586', TensorProto.INT32, shape=None),
            helper.make_tensor_value_info('587', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('589', TensorProto.BOOL, shape=None),
            helper.make_tensor_value_info('592', TensorProto.INT32, shape=None),
            helper.make_tensor_value_info('611', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('612', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('626', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('637', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('638', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('652', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('653', TensorProto.INT64, shape=None),
            helper.make_tensor_value_info('654', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('656', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('659', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('660', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('661', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('173', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('214', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('216', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('229', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('231', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('240', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('242', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('255', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('296', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('298', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('311', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('313', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('322', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('324', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('337', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('378', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('380', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('393', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('395', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('404', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('406', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('419', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('421', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('422', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('423', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('470', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('471', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('487', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('468', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('488', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('489', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('491', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('534', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('536', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('549', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('551', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('560', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('562', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('575', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('608', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('610', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('623', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('625', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('634', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('636', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('649', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('651', TensorProto.FLOAT16, shape=None),
            helper.make_tensor_value_info('graph_output_cast_0', TensorProto.FLOAT16, shape=[1, 255, 1]),
            helper.make_tensor_value_info('graph_output_cast_1', TensorProto.FLOAT16, shape=['Softmax663_dim_0', 5]),
            helper.make_tensor_value_info('MatMul_364_input_cast_0', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('MatMul_364_input_cast_1', TensorProto.FLOAT, shape=[768, 1]),
            helper.make_tensor_value_info('MatMul_364_output_cast_0', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Add_365_input_cast_0', TensorProto.FLOAT, shape=[1]),
            helper.make_tensor_value_info('Add_365_input_cast_1', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Add_365_output_cast_0', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Where_372_input_cast_1', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Where_372_input_cast_2', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Where_372_output_cast_0', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Transpose_373_input_cast_0', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Transpose_373_output_cast_0', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Softmax_374_input_cast_0', TensorProto.FLOAT, shape=None),
            helper.make_tensor_value_info('Softmax_374_output_cast_0', TensorProto.FLOAT, shape=None),
        ],
        nodes=[
            make_node('Equal', inputs=['input_ids', '147'], outputs=['148'], name='Equal_11'),
            make_node('Not', inputs=['148'], outputs=['149'], name='Not_12'),
            make_node('Cast', inputs=['149'], outputs=['150'], name='Cast_13', to=TensorProto.INT32),
            make_node('CumSum', inputs=['150', '151'], outputs=['152'], name='CumSum_15', reverse=0, exclusive=0),
            make_node('Mul', inputs=['152', '150'], outputs=['153'], name='Mul_16'),
            make_node('Cast', inputs=['153'], outputs=['154'], name='Cast_17', to=TensorProto.INT64),
            make_node('Add', inputs=['154', '155'], outputs=['156'], name='Add_19'),
            make_node('Gather', inputs=['longformer.embeddings.position_embeddings.weight', '156'], outputs=['159'], name='Gather_22', axis=0),
            make_node('Gather', inputs=['longformer.embeddings.word_embeddings.weight', 'input_ids'], outputs=['158'], name='Gather_21', axis=0),
            make_node('Add', inputs=['158', '159'], outputs=['161'], name='Add_24'),
            make_node('Gather', inputs=['longformer.embeddings.token_type_embeddings.weight', 'token_type_ids'], outputs=['160'], name='Gather_23', axis=0),
            make_node('Add', inputs=['161', '160'], outputs=['162'], name='Add_25'),
            make_node('QuantizeWithOrder', inputs=['162', '162_scale'], outputs=['162_s8_COL32'], name='162_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.embeddings.LayerNorm.weight', 'longformer.embeddings.LayerNorm.weight_scale'],
                outputs=['longformer.embeddings.LayerNorm.weight_s8_COL32'],
                name='longformer.embeddings.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.embeddings.LayerNorm.bias', 'longformer.embeddings.LayerNorm.bias_scale'],
                outputs=['longformer.embeddings.LayerNorm.bias_s8_COL32'],
                name='longformer.embeddings.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '162_s8_COL32',
                    '162_scale',
                    'longformer.embeddings.LayerNorm.weight_s8_COL32',
                    'longformer.embeddings.LayerNorm.weight_scale',
                    'longformer.embeddings.LayerNorm.bias_s8_COL32',
                    'longformer.embeddings.LayerNorm.bias_scale',
                    '173_scale',
                ],
                outputs=['173_s8_COL32'],
                name='LayerNormalization_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('Add', inputs=['global_attention_mask', '137'], outputs=['138'], name='Add_1'),
            make_node('Mul', inputs=['attention_mask', '138'], outputs=['139'], name='Mul_2'),
            make_node('Unsqueeze', inputs=['139'], outputs=['140'], name='Unsqueeze_3', axes=[1]),
            make_node('Unsqueeze', inputs=['140'], outputs=['141'], name='Unsqueeze_4', axes=[2]),
            make_node('Cast', inputs=['141'], outputs=['142'], name='Cast_5', to=TensorProto.FLOAT16),
            make_node('Sub', inputs=['143', '142'], outputs=['144'], name='Sub_7'),
            make_node('Mul', inputs=['144', '145'], outputs=['146'], name='Mul_9'),
            make_node('Squeeze', inputs=['146'], outputs=['338'], name='Squeeze_135', axes=[2]),
            make_node('Squeeze', inputs=['338'], outputs=['339'], name='Squeeze_136', axes=[1]),
            make_node('Greater', inputs=['339', '179'], outputs=['180'], name='Greater_43'),
            make_node('Where', inputs=['180', '182', '339'], outputs=['183'], name='Where_46'),
            make_node('Greater', inputs=['339', '176'], outputs=['177'], name='Greater_40'),
            make_node('Cast', inputs=['177'], outputs=['178'], name='Cast_41', to=TensorProto.INT32),
            make_node('QuantizeWithOrder', inputs=['671', '671_scale'], outputs=['671_s8_COL32_2R_4R4'], name='671_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['676', '676_scale'], outputs=['676_s8_COL32'], name='676_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node('QuantizeWithOrder', inputs=['684', '684_scale'], outputs=['684_s8_COL32_2R_4R4'], name='684_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['689', '689_scale'], outputs=['689_s8_COL32'], name='689_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node(
                'QOrderedLongformerAttention',
                inputs=['173_s8_COL32', '173_scale', '671_s8_COL32_2R_4R4', '671_scale', '676_s8_COL32', '676_scale', '183', '684_s8_COL32_2R_4R4', '684_scale', '689_s8_COL32', '689_scale', '178', '214_scale'],
                outputs=['214_s8_COL32'],
                name='LongformerAttention_47_quantized',
                domain='com.microsoft',
                num_heads=12,
                order_bias=2,
                order_global_bias=2,
                order_globale_weight=4,
                order_input=2,
                order_output=2,
                order_weight=4,
                window=256,
            ),
            make_node('QuantizeWithOrder', inputs=['690', '690_scale'], outputs=['690_s8_COL32_2R_4R4'], name='690_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['214_s8_COL32', '214_scale', '690_s8_COL32_2R_4R4', '690_scale', '216_scale'],
                outputs=['216_s8_COL32'],
                name='MatMul_48_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.0.attention.output.dense.bias', 'longformer.encoder.layer.0.attention.output.dense.bias_scale'],
                outputs=['longformer.encoder.layer.0.attention.output.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.0.attention.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['longformer.encoder.layer.0.attention.output.dense.bias_s8_COL32', 'longformer.encoder.layer.0.attention.output.dense.bias_scale', '216_s8_COL32', '216_scale', '217_scale'],
                outputs=['217_s8_COL32'],
                name='Add_49_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['217_s8_COL32', '217_scale', '173_s8_COL32', '173_scale', '218_scale'],
                outputs=['218_s8_COL32'],
                name='Add_50_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.0.attention.output.LayerNorm.weight', 'longformer.encoder.layer.0.attention.output.LayerNorm.weight_scale'],
                outputs=['longformer.encoder.layer.0.attention.output.LayerNorm.weight_s8_COL32'],
                name='longformer.encoder.layer.0.attention.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.0.attention.output.LayerNorm.bias', 'longformer.encoder.layer.0.attention.output.LayerNorm.bias_scale'],
                outputs=['longformer.encoder.layer.0.attention.output.LayerNorm.bias_s8_COL32'],
                name='longformer.encoder.layer.0.attention.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '218_s8_COL32',
                    '218_scale',
                    'longformer.encoder.layer.0.attention.output.LayerNorm.weight_s8_COL32',
                    'longformer.encoder.layer.0.attention.output.LayerNorm.weight_scale',
                    'longformer.encoder.layer.0.attention.output.LayerNorm.bias_s8_COL32',
                    'longformer.encoder.layer.0.attention.output.LayerNorm.bias_scale',
                    '229_scale',
                ],
                outputs=['229_s8_COL32'],
                name='LayerNormalization_token_4_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('QuantizeWithOrder', inputs=['691', '691_scale'], outputs=['691_s8_COL32_2R_4R4'], name='691_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['229_s8_COL32', '229_scale', '691_s8_COL32_2R_4R4', '691_scale', '231_scale'],
                outputs=['231_s8_COL32'],
                name='MatMul_62_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.0.intermediate.dense.bias', 'longformer.encoder.layer.0.intermediate.dense.bias_scale'],
                outputs=['longformer.encoder.layer.0.intermediate.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.0.intermediate.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedBiasGelu',
                inputs=['231_s8_COL32', '231_scale', 'longformer.encoder.layer.0.intermediate.dense.bias_s8_COL32', 'longformer.encoder.layer.0.intermediate.dense.bias_scale', '240_scale'],
                outputs=['240_s8_COL32'],
                name='BiasGelu_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node('QuantizeWithOrder', inputs=['692', '692_scale'], outputs=['692_s8_COL32_2R_4R4'], name='692_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['240_s8_COL32', '240_scale', '692_s8_COL32_2R_4R4', '692_scale', '242_scale'],
                outputs=['242_s8_COL32'],
                name='MatMul_72_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.0.output.dense.bias', 'longformer.encoder.layer.0.output.dense.bias_scale'],
                outputs=['longformer.encoder.layer.0.output.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.0.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['longformer.encoder.layer.0.output.dense.bias_s8_COL32', 'longformer.encoder.layer.0.output.dense.bias_scale', '242_s8_COL32', '242_scale', '243_scale'],
                outputs=['243_s8_COL32'],
                name='Add_73_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['243_s8_COL32', '243_scale', '229_s8_COL32', '229_scale', '244_scale'],
                outputs=['244_s8_COL32'],
                name='Add_74_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.0.output.LayerNorm.weight', 'longformer.encoder.layer.0.output.LayerNorm.weight_scale'],
                outputs=['longformer.encoder.layer.0.output.LayerNorm.weight_s8_COL32'],
                name='longformer.encoder.layer.0.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.0.output.LayerNorm.bias', 'longformer.encoder.layer.0.output.LayerNorm.bias_scale'],
                outputs=['longformer.encoder.layer.0.output.LayerNorm.bias_s8_COL32'],
                name='longformer.encoder.layer.0.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '244_s8_COL32',
                    '244_scale',
                    'longformer.encoder.layer.0.output.LayerNorm.weight_s8_COL32',
                    'longformer.encoder.layer.0.output.LayerNorm.weight_scale',
                    'longformer.encoder.layer.0.output.LayerNorm.bias_s8_COL32',
                    'longformer.encoder.layer.0.output.LayerNorm.bias_scale',
                    '255_scale',
                ],
                outputs=['255_s8_COL32'],
                name='LayerNormalization_token_5_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('Greater', inputs=['339', '261'], outputs=['262'], name='Greater_92'),
            make_node('Where', inputs=['262', '264', '339'], outputs=['265'], name='Where_95'),
            make_node('Greater', inputs=['339', '258'], outputs=['259'], name='Greater_89'),
            make_node('Cast', inputs=['259'], outputs=['260'], name='Cast_90', to=TensorProto.INT32),
            make_node('QuantizeWithOrder', inputs=['700', '700_scale'], outputs=['700_s8_COL32_2R_4R4'], name='700_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['705', '705_scale'], outputs=['705_s8_COL32'], name='705_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node('QuantizeWithOrder', inputs=['713', '713_scale'], outputs=['713_s8_COL32_2R_4R4'], name='713_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['718', '718_scale'], outputs=['718_s8_COL32'], name='718_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node(
                'QOrderedLongformerAttention',
                inputs=['255_s8_COL32', '255_scale', '700_s8_COL32_2R_4R4', '700_scale', '705_s8_COL32', '705_scale', '265', '713_s8_COL32_2R_4R4', '713_scale', '718_s8_COL32', '718_scale', '260', '296_scale'],
                outputs=['296_s8_COL32'],
                name='LongformerAttention_96_quantized',
                domain='com.microsoft',
                num_heads=12,
                order_bias=2,
                order_global_bias=2,
                order_globale_weight=4,
                order_input=2,
                order_output=2,
                order_weight=4,
                window=256,
            ),
            make_node('QuantizeWithOrder', inputs=['719', '719_scale'], outputs=['719_s8_COL32_2R_4R4'], name='719_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['296_s8_COL32', '296_scale', '719_s8_COL32_2R_4R4', '719_scale', '298_scale'],
                outputs=['298_s8_COL32'],
                name='MatMul_97_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.1.attention.output.dense.bias', 'longformer.encoder.layer.1.attention.output.dense.bias_scale'],
                outputs=['longformer.encoder.layer.1.attention.output.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.1.attention.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['longformer.encoder.layer.1.attention.output.dense.bias_s8_COL32', 'longformer.encoder.layer.1.attention.output.dense.bias_scale', '298_s8_COL32', '298_scale', '299_scale'],
                outputs=['299_s8_COL32'],
                name='Add_98_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['299_s8_COL32', '299_scale', '255_s8_COL32', '255_scale', '300_scale'],
                outputs=['300_s8_COL32'],
                name='Add_99_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.1.attention.output.LayerNorm.weight', 'longformer.encoder.layer.1.attention.output.LayerNorm.weight_scale'],
                outputs=['longformer.encoder.layer.1.attention.output.LayerNorm.weight_s8_COL32'],
                name='longformer.encoder.layer.1.attention.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.1.attention.output.LayerNorm.bias', 'longformer.encoder.layer.1.attention.output.LayerNorm.bias_scale'],
                outputs=['longformer.encoder.layer.1.attention.output.LayerNorm.bias_s8_COL32'],
                name='longformer.encoder.layer.1.attention.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '300_s8_COL32',
                    '300_scale',
                    'longformer.encoder.layer.1.attention.output.LayerNorm.weight_s8_COL32',
                    'longformer.encoder.layer.1.attention.output.LayerNorm.weight_scale',
                    'longformer.encoder.layer.1.attention.output.LayerNorm.bias_s8_COL32',
                    'longformer.encoder.layer.1.attention.output.LayerNorm.bias_scale',
                    '311_scale',
                ],
                outputs=['311_s8_COL32'],
                name='LayerNormalization_token_6_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('QuantizeWithOrder', inputs=['720', '720_scale'], outputs=['720_s8_COL32_2R_4R4'], name='720_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['311_s8_COL32', '311_scale', '720_s8_COL32_2R_4R4', '720_scale', '313_scale'],
                outputs=['313_s8_COL32'],
                name='MatMul_111_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.1.intermediate.dense.bias', 'longformer.encoder.layer.1.intermediate.dense.bias_scale'],
                outputs=['longformer.encoder.layer.1.intermediate.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.1.intermediate.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedBiasGelu',
                inputs=['313_s8_COL32', '313_scale', 'longformer.encoder.layer.1.intermediate.dense.bias_s8_COL32', 'longformer.encoder.layer.1.intermediate.dense.bias_scale', '322_scale'],
                outputs=['322_s8_COL32'],
                name='BiasGelu_token_14_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node('QuantizeWithOrder', inputs=['721', '721_scale'], outputs=['721_s8_COL32_2R_4R4'], name='721_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['322_s8_COL32', '322_scale', '721_s8_COL32_2R_4R4', '721_scale', '324_scale'],
                outputs=['324_s8_COL32'],
                name='MatMul_121_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.1.output.dense.bias', 'longformer.encoder.layer.1.output.dense.bias_scale'],
                outputs=['longformer.encoder.layer.1.output.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.1.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['longformer.encoder.layer.1.output.dense.bias_s8_COL32', 'longformer.encoder.layer.1.output.dense.bias_scale', '324_s8_COL32', '324_scale', '325_scale'],
                outputs=['325_s8_COL32'],
                name='Add_122_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['325_s8_COL32', '325_scale', '311_s8_COL32', '311_scale', '326_scale'],
                outputs=['326_s8_COL32'],
                name='Add_123_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.1.output.LayerNorm.weight', 'longformer.encoder.layer.1.output.LayerNorm.weight_scale'],
                outputs=['longformer.encoder.layer.1.output.LayerNorm.weight_s8_COL32'],
                name='longformer.encoder.layer.1.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.1.output.LayerNorm.bias', 'longformer.encoder.layer.1.output.LayerNorm.bias_scale'],
                outputs=['longformer.encoder.layer.1.output.LayerNorm.bias_s8_COL32'],
                name='longformer.encoder.layer.1.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '326_s8_COL32',
                    '326_scale',
                    'longformer.encoder.layer.1.output.LayerNorm.weight_s8_COL32',
                    'longformer.encoder.layer.1.output.LayerNorm.weight_scale',
                    'longformer.encoder.layer.1.output.LayerNorm.bias_s8_COL32',
                    'longformer.encoder.layer.1.output.LayerNorm.bias_scale',
                    '337_scale',
                ],
                outputs=['337_s8_COL32'],
                name='LayerNormalization_token_7_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('Greater', inputs=['339', '343'], outputs=['344'], name='Greater_141'),
            make_node('Where', inputs=['344', '346', '339'], outputs=['347'], name='Where_144'),
            make_node('Greater', inputs=['339', '340'], outputs=['341'], name='Greater_138'),
            make_node('Cast', inputs=['341'], outputs=['342'], name='Cast_139', to=TensorProto.INT32),
            make_node('QuantizeWithOrder', inputs=['729', '729_scale'], outputs=['729_s8_COL32_2R_4R4'], name='729_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['734', '734_scale'], outputs=['734_s8_COL32'], name='734_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node('QuantizeWithOrder', inputs=['742', '742_scale'], outputs=['742_s8_COL32_2R_4R4'], name='742_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['747', '747_scale'], outputs=['747_s8_COL32'], name='747_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node(
                'QOrderedLongformerAttention',
                inputs=['337_s8_COL32', '337_scale', '729_s8_COL32_2R_4R4', '729_scale', '734_s8_COL32', '734_scale', '347', '742_s8_COL32_2R_4R4', '742_scale', '747_s8_COL32', '747_scale', '342', '378_scale'],
                outputs=['378_s8_COL32'],
                name='LongformerAttention_145_quantized',
                domain='com.microsoft',
                num_heads=12,
                order_bias=2,
                order_global_bias=2,
                order_globale_weight=4,
                order_input=2,
                order_output=2,
                order_weight=4,
                window=256,
            ),
            make_node('QuantizeWithOrder', inputs=['748', '748_scale'], outputs=['748_s8_COL32_2R_4R4'], name='748_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['378_s8_COL32', '378_scale', '748_s8_COL32_2R_4R4', '748_scale', '380_scale'],
                outputs=['380_s8_COL32'],
                name='MatMul_146_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.2.attention.output.dense.bias', 'longformer.encoder.layer.2.attention.output.dense.bias_scale'],
                outputs=['longformer.encoder.layer.2.attention.output.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.2.attention.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['longformer.encoder.layer.2.attention.output.dense.bias_s8_COL32', 'longformer.encoder.layer.2.attention.output.dense.bias_scale', '380_s8_COL32', '380_scale', '381_scale'],
                outputs=['381_s8_COL32'],
                name='Add_147_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['381_s8_COL32', '381_scale', '337_s8_COL32', '337_scale', '382_scale'],
                outputs=['382_s8_COL32'],
                name='Add_148_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.2.attention.output.LayerNorm.weight', 'longformer.encoder.layer.2.attention.output.LayerNorm.weight_scale'],
                outputs=['longformer.encoder.layer.2.attention.output.LayerNorm.weight_s8_COL32'],
                name='longformer.encoder.layer.2.attention.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.2.attention.output.LayerNorm.bias', 'longformer.encoder.layer.2.attention.output.LayerNorm.bias_scale'],
                outputs=['longformer.encoder.layer.2.attention.output.LayerNorm.bias_s8_COL32'],
                name='longformer.encoder.layer.2.attention.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '382_s8_COL32',
                    '382_scale',
                    'longformer.encoder.layer.2.attention.output.LayerNorm.weight_s8_COL32',
                    'longformer.encoder.layer.2.attention.output.LayerNorm.weight_scale',
                    'longformer.encoder.layer.2.attention.output.LayerNorm.bias_s8_COL32',
                    'longformer.encoder.layer.2.attention.output.LayerNorm.bias_scale',
                    '393_scale',
                ],
                outputs=['393_s8_COL32'],
                name='LayerNormalization_token_8_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('QuantizeWithOrder', inputs=['749', '749_scale'], outputs=['749_s8_COL32_2R_4R4'], name='749_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['393_s8_COL32', '393_scale', '749_s8_COL32_2R_4R4', '749_scale', '395_scale'],
                outputs=['395_s8_COL32'],
                name='MatMul_160_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.2.intermediate.dense.bias', 'longformer.encoder.layer.2.intermediate.dense.bias_scale'],
                outputs=['longformer.encoder.layer.2.intermediate.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.2.intermediate.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedBiasGelu',
                inputs=['395_s8_COL32', '395_scale', 'longformer.encoder.layer.2.intermediate.dense.bias_s8_COL32', 'longformer.encoder.layer.2.intermediate.dense.bias_scale', '404_scale'],
                outputs=['404_s8_COL32'],
                name='BiasGelu_token_15_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node('QuantizeWithOrder', inputs=['750', '750_scale'], outputs=['750_s8_COL32_2R_4R4'], name='750_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['404_s8_COL32', '404_scale', '750_s8_COL32_2R_4R4', '750_scale', '406_scale'],
                outputs=['406_s8_COL32'],
                name='MatMul_170_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.2.output.dense.bias', 'longformer.encoder.layer.2.output.dense.bias_scale'],
                outputs=['longformer.encoder.layer.2.output.dense.bias_s8_COL32'],
                name='longformer.encoder.layer.2.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['longformer.encoder.layer.2.output.dense.bias_s8_COL32', 'longformer.encoder.layer.2.output.dense.bias_scale', '406_s8_COL32', '406_scale', '407_scale'],
                outputs=['407_s8_COL32'],
                name='Add_171_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['407_s8_COL32', '407_scale', '393_s8_COL32', '393_scale', '408_scale'],
                outputs=['408_s8_COL32'],
                name='Add_172_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.2.output.LayerNorm.weight', 'longformer.encoder.layer.2.output.LayerNorm.weight_scale'],
                outputs=['longformer.encoder.layer.2.output.LayerNorm.weight_s8_COL32'],
                name='longformer.encoder.layer.2.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['longformer.encoder.layer.2.output.LayerNorm.bias', 'longformer.encoder.layer.2.output.LayerNorm.bias_scale'],
                outputs=['longformer.encoder.layer.2.output.LayerNorm.bias_s8_COL32'],
                name='longformer.encoder.layer.2.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '408_s8_COL32',
                    '408_scale',
                    'longformer.encoder.layer.2.output.LayerNorm.weight_s8_COL32',
                    'longformer.encoder.layer.2.output.LayerNorm.weight_scale',
                    'longformer.encoder.layer.2.output.LayerNorm.bias_s8_COL32',
                    'longformer.encoder.layer.2.output.LayerNorm.bias_scale',
                    '419_scale',
                ],
                outputs=['419_s8_COL32'],
                name='LayerNormalization_token_9_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('DequantizeWithOrder', inputs=['419_s8_COL32', '419_scale'], outputs=['419'], name='419_DequantizeWithOrder', domain='com.microsoft', order_input=2, order_output=0, to=10),
            make_node('Gather', inputs=['419', '420'], outputs=['421'], name='Gather_185', axis=1),
            make_node('Gemm', inputs=['421', 'ranking_outputs_onedcg.projection.weight', 'ranking_outputs_onedcg.projection.bias'], outputs=['422'], name='Gemm_186', alpha=1.0, beta=1.0, transA=0, transB=1),
            make_node('Softmax', inputs=['422'], outputs=['graph_output_cast_1'], name='Softmax_376', axis=1),
            make_node('Shape', inputs=['sen_lens'], outputs=['427'], name='Shape_191'),
            make_node('Gather', inputs=['427', '428'], outputs=['429'], name='Gather_193', axis=0),
            make_node(
                'Loop',
                inputs=['429', '424', '426'],
                outputs=['430'],
                name='Loop_194',
                body=make_graph(
                    name='torch-jit-export1',
                    inputs=[
                        helper.make_tensor_value_info('batch_id.1', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('cond', TensorProto.BOOL, shape=[]),
                        helper.make_tensor_value_info('masks.11', TensorProto.FLOAT16, shape=[0, 256]),
                    ],
                    outputs=[helper.make_tensor_value_info('457', TensorProto.BOOL, shape=[]), helper.make_tensor_value_info('456', TensorProto.FLOAT16, shape=[1, 256])],
                    initializer=[
                        numpy_helper.from_array(np.array(0, dtype='int64'), name='438'),
                        numpy_helper.from_array(np.array(256, dtype='int64'), name='440'),
                        numpy_helper.from_array(np.array(256, dtype='int64'), name='449'),
                        numpy_helper.from_array(np.array(True, dtype='bool'), name='457'),
                    ],
                    doc_string='',
                    value_info=[
                        helper.make_tensor_value_info('434', TensorProto.INT64, shape=['seq_len']),
                        helper.make_tensor_value_info('435', TensorProto.INT64, shape=None),
                        helper.make_tensor_value_info('436', TensorProto.INT64, shape=None),
                        helper.make_tensor_value_info('437', TensorProto.INT64, shape=None),
                        helper.make_tensor_value_info('439', TensorProto.INT64, shape=None),
                        helper.make_tensor_value_info('441', TensorProto.BOOL, shape=None),
                        helper.make_tensor_value_info('443', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('450', TensorProto.INT64, shape=[]),
                        helper.make_tensor_value_info('451', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('452_CUDAExecutionProvider', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('453', TensorProto.FLOAT16, shape=None),
                        helper.make_tensor_value_info('446', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('447_CUDAExecutionProvider', TensorProto.INT64, shape=[1]),
                        helper.make_tensor_value_info('448', TensorProto.FLOAT16, shape=None),
                        helper.make_tensor_value_info('454', TensorProto.FLOAT16, shape=None),
                        helper.make_tensor_value_info('455', TensorProto.FLOAT16, shape=None),
                    ],
                    nodes=[
                        make_node('Gather', inputs=['sen_lens', 'batch_id.1'], outputs=['434'], name='Gather_195', axis=0),
                        make_node('NonZero', inputs=['434'], outputs=['435'], name='NonZero_196'),
                        make_node('Transpose', inputs=['435'], outputs=['436'], name='Transpose_197', perm=[1, 0]),
                        make_node('Shape', inputs=['436'], outputs=['437'], name='Shape_198'),
                        make_node('Gather', inputs=['437', '438'], outputs=['439'], name='Gather_200', axis=0),
                        make_node('GreaterOrEqual', inputs=['439', '440'], outputs=['441'], name='GreaterOrEqual_202'),
                        make_node(
                            'If',
                            inputs=['441'],
                            outputs=['443'],
                            name='If_204',
                            else_branch=make_graph(
                                name='torch-jit-export3',
                                inputs=[],
                                outputs=[helper.make_tensor_value_info('445', TensorProto.INT64, shape=[])],
                                doc_string='',
                                nodes=[make_node('Identity', inputs=['439'], outputs=['445'], name='Identity_206')],
                            ),
                            then_branch=make_graph(
                                name='torch-jit-export2',
                                inputs=[],
                                outputs=[helper.make_tensor_value_info('444', TensorProto.INT64, shape=[])],
                                initializer=[numpy_helper.from_array(np.array(255, dtype='int64'), name='444')],
                                doc_string='',
                                nodes=[],
                            ),
                        ),
                        make_node('Sub', inputs=['449', '443'], outputs=['450'], name='Sub_211'),
                        make_node('Unsqueeze', inputs=['450'], outputs=['451'], name='Unsqueeze_212', axes=[0]),
                        make_node('Concat', inputs=['451'], outputs=['452_CUDAExecutionProvider'], name='Concat_213', axis=0),
                        make_node('MemcpyToHost', inputs=['452_CUDAExecutionProvider'], outputs=['452'], name='Memcpy_token_0', doc_string='Copy from/to host memory'),
                        make_node('ConstantOfShape', inputs=['452'], outputs=['453'], name='ConstantOfShape_214', value=numpy_helper.from_array(np.array([0.0], dtype='float16'), name='')),
                        make_node('Unsqueeze', inputs=['443'], outputs=['446'], name='Unsqueeze_207', axes=[0]),
                        make_node('Concat', inputs=['446'], outputs=['447_CUDAExecutionProvider'], name='Concat_208', axis=0),
                        make_node('MemcpyToHost', inputs=['447_CUDAExecutionProvider'], outputs=['447'], name='Memcpy', doc_string='Copy from/to host memory'),
                        make_node('ConstantOfShape', inputs=['447'], outputs=['448'], name='ConstantOfShape_209', value=numpy_helper.from_array(np.array([1.0], dtype='float16'), name='')),
                        make_node('Concat', inputs=['448', '453'], outputs=['454'], name='Concat_215', axis=0),
                        make_node('Unsqueeze', inputs=['454'], outputs=['455'], name='Unsqueeze_216', axes=[0]),
                        make_node('Concat', inputs=['masks.11', '455'], outputs=['456'], name='Concat_217', axis=0),
                    ],
                ),
            ),
            make_node('Unsqueeze', inputs=['430'], outputs=['458'], name='Unsqueeze_219', axes=[-1]),
            make_node('Slice', inputs=['458', '460', '461', '459', '462'], outputs=['463'], name='Slice_224'),
            make_node('Equal', inputs=['463', '657'], outputs=['658'], name='Equal_371'),
            make_node('SequencePooling', inputs=['419', 'sen_lens'], outputs=['423'], name='SequencePooling_187', domain='com.microsoft'),
            make_node('Gather', inputs=['423', '469'], outputs=['470'], name='Gather_231', axis=1),
            make_node('Unsqueeze', inputs=['470'], outputs=['471'], name='Unsqueeze_232', axes=[1]),
            make_node('Expand', inputs=['471', '486'], outputs=['487'], name='Expand_242'),
            make_node('Slice', inputs=['423', '465', '466', '464', '467'], outputs=['468'], name='Slice_229'),
            make_node('Shape', inputs=['468'], outputs=['472'], name='Shape_233'),
            make_node('Gather', inputs=['472', '473'], outputs=['474'], name='Gather_235', axis=0),
            make_node('Unsqueeze', inputs=['474'], outputs=['478'], name='Unsqueeze_236', axes=[0]),
            make_node('Concat', inputs=['753', '478', '754'], outputs=['484'], name='Concat_239', axis=0),
            make_node('Tile', inputs=['487', '484'], outputs=['488'], name='Tile_243'),
            make_node('Concat', inputs=['488', '468'], outputs=['489'], name='Concat_244', axis=-1),
            make_node('QuantizeWithOrder', inputs=['489', '489_scale'], outputs=['489_s8_COL32'], name='489_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node('QuantizeWithOrder', inputs=['755', '755_scale'], outputs=['755_s8_COL32_2R_4R4'], name='755_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['489_s8_COL32', '489_scale', '755_s8_COL32_2R_4R4', '755_scale', '491_scale'],
                outputs=['491_s8_COL32'],
                name='MatMul_245_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['MiddleLayer_2hiddensize_hiddensize.projection.bias', 'MiddleLayer_2hiddensize_hiddensize.projection.bias_scale'],
                outputs=['MiddleLayer_2hiddensize_hiddensize.projection.bias_s8_COL32'],
                name='MiddleLayer_2hiddensize_hiddensize.projection.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['MiddleLayer_2hiddensize_hiddensize.projection.bias_s8_COL32', 'MiddleLayer_2hiddensize_hiddensize.projection.bias_scale', '491_s8_COL32', '491_scale', '492_scale'],
                outputs=['492_s8_COL32'],
                name='Add_246_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node('Shape', inputs=['492_s8_COL32'], outputs=['503'], name='Shape_257'),
            make_node('Gather', inputs=['503', '504'], outputs=['505'], name='Gather_259', axis=0),
            make_node('Unsqueeze', inputs=['505'], outputs=['507'], name='Unsqueeze_260', axes=[0]),
            make_node('Concat', inputs=['507', '756'], outputs=['509'], name='Concat_261', axis=0),
            make_node('Squeeze', inputs=['463'], outputs=['494'], name='Squeeze_248', axes=[2]),
            make_node('Unsqueeze', inputs=['494'], outputs=['495'], name='Unsqueeze_249', axes=[1]),
            make_node('Unsqueeze', inputs=['495'], outputs=['496'], name='Unsqueeze_250', axes=[2]),
            make_node('Sub', inputs=['498', '496'], outputs=['499'], name='Sub_253'),
            make_node('Mul', inputs=['499', '500'], outputs=['501'], name='Mul_255'),
            make_node('Cast', inputs=['501'], outputs=['502'], name='Cast_256', to=TensorProto.INT32),
            make_node('Reshape', inputs=['502', '509'], outputs=['510'], name='Reshape_262'),
            make_node('Add', inputs=['510', '511'], outputs=['512'], name='Add_264'),
            make_node('Cast', inputs=['512'], outputs=['513'], name='Cast_265', to=TensorProto.INT64),
            make_node('Greater', inputs=['513', '514'], outputs=['515'], name='Greater_267'),
            make_node('Where', inputs=['515', '517', '512'], outputs=['518'], name='Where_270'),
            make_node('QuantizeWithOrder', inputs=['764', '764_scale'], outputs=['764_s8_COL32_2R_4R4'], name='764_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['769', '769_scale'], outputs=['769_s8_COL32'], name='769_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node(
                'QOrderedAttention',
                inputs=['492_s8_COL32', '492_scale', '764_s8_COL32_2R_4R4', '764_scale', '769_s8_COL32', '769_scale', '518', '534_scale'],
                outputs=['534_s8_COL32'],
                name='Attention_271_quantized',
                domain='com.microsoft',
                num_heads=12,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_weight=4,
                unidirectional=0,
            ),
            make_node('QuantizeWithOrder', inputs=['770', '770_scale'], outputs=['770_s8_COL32_2R_4R4'], name='770_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['534_s8_COL32', '534_scale', '770_s8_COL32_2R_4R4', '770_scale', '536_scale'],
                outputs=['536_s8_COL32'],
                name='MatMul_272_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.0.attention.output.dense.bias', 'sentence_wise_att.layer.0.attention.output.dense.bias_scale'],
                outputs=['sentence_wise_att.layer.0.attention.output.dense.bias_s8_COL32'],
                name='sentence_wise_att.layer.0.attention.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['sentence_wise_att.layer.0.attention.output.dense.bias_s8_COL32', 'sentence_wise_att.layer.0.attention.output.dense.bias_scale', '536_s8_COL32', '536_scale', '537_scale'],
                outputs=['537_s8_COL32'],
                name='Add_273_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['537_s8_COL32', '537_scale', '492_s8_COL32', '492_scale', '538_scale'],
                outputs=['538_s8_COL32'],
                name='Add_274_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.0.attention.output.LayerNorm.weight', 'sentence_wise_att.layer.0.attention.output.LayerNorm.weight_scale'],
                outputs=['sentence_wise_att.layer.0.attention.output.LayerNorm.weight_s8_COL32'],
                name='sentence_wise_att.layer.0.attention.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.0.attention.output.LayerNorm.bias', 'sentence_wise_att.layer.0.attention.output.LayerNorm.bias_scale'],
                outputs=['sentence_wise_att.layer.0.attention.output.LayerNorm.bias_s8_COL32'],
                name='sentence_wise_att.layer.0.attention.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '538_s8_COL32',
                    '538_scale',
                    'sentence_wise_att.layer.0.attention.output.LayerNorm.weight_s8_COL32',
                    'sentence_wise_att.layer.0.attention.output.LayerNorm.weight_scale',
                    'sentence_wise_att.layer.0.attention.output.LayerNorm.bias_s8_COL32',
                    'sentence_wise_att.layer.0.attention.output.LayerNorm.bias_scale',
                    '549_scale',
                ],
                outputs=['549_s8_COL32'],
                name='LayerNormalization_token_10_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('QuantizeWithOrder', inputs=['771', '771_scale'], outputs=['771_s8_COL32_2R_4R4'], name='771_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['549_s8_COL32', '549_scale', '771_s8_COL32_2R_4R4', '771_scale', '551_scale'],
                outputs=['551_s8_COL32'],
                name='MatMul_286_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.0.intermediate.dense.bias', 'sentence_wise_att.layer.0.intermediate.dense.bias_scale'],
                outputs=['sentence_wise_att.layer.0.intermediate.dense.bias_s8_COL32'],
                name='sentence_wise_att.layer.0.intermediate.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['sentence_wise_att.layer.0.intermediate.dense.bias_s8_COL32', 'sentence_wise_att.layer.0.intermediate.dense.bias_scale', '551_s8_COL32', '551_scale', '552_scale'],
                outputs=['552_s8_COL32'],
                name='Add_287_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node('QOrderedGelu', inputs=['552_s8_COL32', '552_scale', '560_scale'], outputs=['560_s8_COL32'], name='Gelu_token_2_quantized', domain='com.microsoft', order_X=2, order_Y=2),
            make_node('QuantizeWithOrder', inputs=['772', '772_scale'], outputs=['772_s8_COL32_2R_4R4'], name='772_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['560_s8_COL32', '560_scale', '772_s8_COL32_2R_4R4', '772_scale', '562_scale'],
                outputs=['562_s8_COL32'],
                name='MatMul_296_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.0.output.dense.bias', 'sentence_wise_att.layer.0.output.dense.bias_scale'],
                outputs=['sentence_wise_att.layer.0.output.dense.bias_s8_COL32'],
                name='sentence_wise_att.layer.0.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['sentence_wise_att.layer.0.output.dense.bias_s8_COL32', 'sentence_wise_att.layer.0.output.dense.bias_scale', '562_s8_COL32', '562_scale', '563_scale'],
                outputs=['563_s8_COL32'],
                name='Add_297_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['563_s8_COL32', '563_scale', '549_s8_COL32', '549_scale', '564_scale'],
                outputs=['564_s8_COL32'],
                name='Add_298_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.0.output.LayerNorm.weight', 'sentence_wise_att.layer.0.output.LayerNorm.weight_scale'],
                outputs=['sentence_wise_att.layer.0.output.LayerNorm.weight_s8_COL32'],
                name='sentence_wise_att.layer.0.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.0.output.LayerNorm.bias', 'sentence_wise_att.layer.0.output.LayerNorm.bias_scale'],
                outputs=['sentence_wise_att.layer.0.output.LayerNorm.bias_s8_COL32'],
                name='sentence_wise_att.layer.0.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '564_s8_COL32',
                    '564_scale',
                    'sentence_wise_att.layer.0.output.LayerNorm.weight_s8_COL32',
                    'sentence_wise_att.layer.0.output.LayerNorm.weight_scale',
                    'sentence_wise_att.layer.0.output.LayerNorm.bias_s8_COL32',
                    'sentence_wise_att.layer.0.output.LayerNorm.bias_scale',
                    '575_scale',
                ],
                outputs=['575_s8_COL32'],
                name='LayerNormalization_token_11_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('Shape', inputs=['575_s8_COL32'], outputs=['577'], name='Shape_311'),
            make_node('Gather', inputs=['577', '578'], outputs=['579'], name='Gather_313', axis=0),
            make_node('Unsqueeze', inputs=['579'], outputs=['581'], name='Unsqueeze_314', axes=[0]),
            make_node('Concat', inputs=['581', '773'], outputs=['583'], name='Concat_315', axis=0),
            make_node('Reshape', inputs=['502', '583'], outputs=['584'], name='Reshape_316'),
            make_node('Add', inputs=['584', '585'], outputs=['586'], name='Add_318'),
            make_node('Cast', inputs=['586'], outputs=['587'], name='Cast_319', to=TensorProto.INT64),
            make_node('Greater', inputs=['587', '588'], outputs=['589'], name='Greater_321'),
            make_node('Where', inputs=['589', '591', '586'], outputs=['592'], name='Where_324'),
            make_node('QuantizeWithOrder', inputs=['781', '781_scale'], outputs=['781_s8_COL32_2R_4R4'], name='781_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node('QuantizeWithOrder', inputs=['786', '786_scale'], outputs=['786_s8_COL32'], name='786_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=2),
            make_node(
                'QOrderedAttention',
                inputs=['575_s8_COL32', '575_scale', '781_s8_COL32_2R_4R4', '781_scale', '786_s8_COL32', '786_scale', '592', '608_scale'],
                outputs=['608_s8_COL32'],
                name='Attention_325_quantized',
                domain='com.microsoft',
                num_heads=12,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_weight=4,
                unidirectional=0,
            ),
            make_node('QuantizeWithOrder', inputs=['787', '787_scale'], outputs=['787_s8_COL32_2R_4R4'], name='787_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['608_s8_COL32', '608_scale', '787_s8_COL32_2R_4R4', '787_scale', '610_scale'],
                outputs=['610_s8_COL32'],
                name='MatMul_326_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.1.attention.output.dense.bias', 'sentence_wise_att.layer.1.attention.output.dense.bias_scale'],
                outputs=['sentence_wise_att.layer.1.attention.output.dense.bias_s8_COL32'],
                name='sentence_wise_att.layer.1.attention.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['sentence_wise_att.layer.1.attention.output.dense.bias_s8_COL32', 'sentence_wise_att.layer.1.attention.output.dense.bias_scale', '610_s8_COL32', '610_scale', '611_scale'],
                outputs=['611_s8_COL32'],
                name='Add_327_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['611_s8_COL32', '611_scale', '575_s8_COL32', '575_scale', '612_scale'],
                outputs=['612_s8_COL32'],
                name='Add_328_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.1.attention.output.LayerNorm.weight', 'sentence_wise_att.layer.1.attention.output.LayerNorm.weight_scale'],
                outputs=['sentence_wise_att.layer.1.attention.output.LayerNorm.weight_s8_COL32'],
                name='sentence_wise_att.layer.1.attention.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.1.attention.output.LayerNorm.bias', 'sentence_wise_att.layer.1.attention.output.LayerNorm.bias_scale'],
                outputs=['sentence_wise_att.layer.1.attention.output.LayerNorm.bias_s8_COL32'],
                name='sentence_wise_att.layer.1.attention.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '612_s8_COL32',
                    '612_scale',
                    'sentence_wise_att.layer.1.attention.output.LayerNorm.weight_s8_COL32',
                    'sentence_wise_att.layer.1.attention.output.LayerNorm.weight_scale',
                    'sentence_wise_att.layer.1.attention.output.LayerNorm.bias_s8_COL32',
                    'sentence_wise_att.layer.1.attention.output.LayerNorm.bias_scale',
                    '623_scale',
                ],
                outputs=['623_s8_COL32'],
                name='LayerNormalization_token_12_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('QuantizeWithOrder', inputs=['788', '788_scale'], outputs=['788_s8_COL32_2R_4R4'], name='788_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['623_s8_COL32', '623_scale', '788_s8_COL32_2R_4R4', '788_scale', '625_scale'],
                outputs=['625_s8_COL32'],
                name='MatMul_340_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.1.intermediate.dense.bias', 'sentence_wise_att.layer.1.intermediate.dense.bias_scale'],
                outputs=['sentence_wise_att.layer.1.intermediate.dense.bias_s8_COL32'],
                name='sentence_wise_att.layer.1.intermediate.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['sentence_wise_att.layer.1.intermediate.dense.bias_s8_COL32', 'sentence_wise_att.layer.1.intermediate.dense.bias_scale', '625_s8_COL32', '625_scale', '626_scale'],
                outputs=['626_s8_COL32'],
                name='Add_341_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node('QOrderedGelu', inputs=['626_s8_COL32', '626_scale', '634_scale'], outputs=['634_s8_COL32'], name='Gelu_token_3_quantized', domain='com.microsoft', order_X=2, order_Y=2),
            make_node('QuantizeWithOrder', inputs=['789', '789_scale'], outputs=['789_s8_COL32_2R_4R4'], name='789_QuantizeWithOrder', domain='com.microsoft', order_input=0, order_output=4),
            make_node(
                'QOrderedMatMul',
                inputs=['634_s8_COL32', '634_scale', '789_s8_COL32_2R_4R4', '789_scale', '636_scale'],
                outputs=['636_s8_COL32'],
                name='MatMul_350_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=4,
                order_Y=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.1.output.dense.bias', 'sentence_wise_att.layer.1.output.dense.bias_scale'],
                outputs=['sentence_wise_att.layer.1.output.dense.bias_s8_COL32'],
                name='sentence_wise_att.layer.1.output.dense.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['sentence_wise_att.layer.1.output.dense.bias_s8_COL32', 'sentence_wise_att.layer.1.output.dense.bias_scale', '636_s8_COL32', '636_scale', '637_scale'],
                outputs=['637_s8_COL32'],
                name='Add_351_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QOrderedAdd',
                inputs=['637_s8_COL32', '637_scale', '623_s8_COL32', '623_scale', '638_scale'],
                outputs=['638_s8_COL32'],
                name='Add_352_quantized',
                domain='com.microsoft',
                order_A=2,
                order_B=2,
                order_C=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.1.output.LayerNorm.weight', 'sentence_wise_att.layer.1.output.LayerNorm.weight_scale'],
                outputs=['sentence_wise_att.layer.1.output.LayerNorm.weight_s8_COL32'],
                name='sentence_wise_att.layer.1.output.LayerNorm.weight_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QuantizeWithOrder',
                inputs=['sentence_wise_att.layer.1.output.LayerNorm.bias', 'sentence_wise_att.layer.1.output.LayerNorm.bias_scale'],
                outputs=['sentence_wise_att.layer.1.output.LayerNorm.bias_s8_COL32'],
                name='sentence_wise_att.layer.1.output.LayerNorm.bias_QuantizeWithOrder',
                domain='com.microsoft',
                order_input=0,
                order_output=2,
            ),
            make_node(
                'QOrderedLayerNormalization',
                inputs=[
                    '638_s8_COL32',
                    '638_scale',
                    'sentence_wise_att.layer.1.output.LayerNorm.weight_s8_COL32',
                    'sentence_wise_att.layer.1.output.LayerNorm.weight_scale',
                    'sentence_wise_att.layer.1.output.LayerNorm.bias_s8_COL32',
                    'sentence_wise_att.layer.1.output.LayerNorm.bias_scale',
                    '649_scale',
                ],
                outputs=['649_s8_COL32'],
                name='LayerNormalization_token_13_quantized',
                domain='com.microsoft',
                axis=-1,
                epsilon=9.999999747378752e-06,
                order_bias=2,
                order_input=2,
                order_output=2,
                order_scale=2,
                stash_type=1,
            ),
            make_node('Cast', inputs=['graph_output_cast_1'], outputs=['663'], name='graph_output_cast1', to=TensorProto.FLOAT),
            make_node('DequantizeWithOrder', inputs=['649_s8_COL32', '649_scale'], outputs=['649'], name='649_DequantizeWithOrder', domain='com.microsoft', order_input=2, order_output=0, to=10),
            make_node('Cast', inputs=['649'], outputs=['MatMul_364_input_cast_0'], name='MatMul_364_input_cast0', to=TensorProto.FLOAT),
            make_node('Cast', inputs=['790'], outputs=['MatMul_364_input_cast_1'], name='MatMul_364_input_cast1', to=TensorProto.FLOAT),
            make_node('MatMul', inputs=['MatMul_364_input_cast_0', 'MatMul_364_input_cast_1'], outputs=['MatMul_364_output_cast_0'], name='MatMul_364'),
            make_node('Cast', inputs=['MatMul_364_output_cast_0'], outputs=['651'], name='MatMul_364_output_cast0', to=TensorProto.FLOAT16),
            make_node('Cast', inputs=['qna_outputs_hiddensize_1.projection.bias'], outputs=['Add_365_input_cast_0'], name='Add_365_input_cast0', to=TensorProto.FLOAT),
            make_node('Cast', inputs=['651'], outputs=['Add_365_input_cast_1'], name='Add_365_input_cast1', to=TensorProto.FLOAT),
            make_node('Add', inputs=['Add_365_input_cast_0', 'Add_365_input_cast_1'], outputs=['Add_365_output_cast_0'], name='Add_365'),
            make_node('Cast', inputs=['Add_365_output_cast_0'], outputs=['652'], name='Add_365_output_cast0', to=TensorProto.FLOAT16),
            make_node('Shape', inputs=['652'], outputs=['653'], name='Shape_366'),
            make_node('ConstantOfShape', inputs=['653'], outputs=['654'], name='ConstantOfShape_367', value=numpy_helper.from_array(np.array([1.0], dtype='float16'), name='')),
            make_node('Mul', inputs=['654', '655'], outputs=['656'], name='Mul_369'),
            make_node('Cast', inputs=['652'], outputs=['Where_372_input_cast_1'], name='Where_372_input_cast1', to=TensorProto.FLOAT),
            make_node('Cast', inputs=['656'], outputs=['Where_372_input_cast_2'], name='Where_372_input_cast2', to=TensorProto.FLOAT),
            make_node('Where', inputs=['658', 'Where_372_input_cast_1', 'Where_372_input_cast_2'], outputs=['Where_372_output_cast_0'], name='Where_372'),
            make_node('Cast', inputs=['Where_372_output_cast_0'], outputs=['659'], name='Where_372_output_cast0', to=TensorProto.FLOAT16),
            make_node('Cast', inputs=['659'], outputs=['Transpose_373_input_cast_0'], name='Transpose_373_input_cast0', to=TensorProto.FLOAT),
            make_node('Transpose', inputs=['Transpose_373_input_cast_0'], outputs=['Transpose_373_output_cast_0'], name='Transpose_373', perm=[0, 2, 1]),
            make_node('Cast', inputs=['Transpose_373_output_cast_0'], outputs=['660'], name='Transpose_373_output_cast0', to=TensorProto.FLOAT16),
            make_node('Cast', inputs=['660'], outputs=['Softmax_374_input_cast_0'], name='Softmax_374_input_cast0', to=TensorProto.FLOAT),
            make_node('Softmax', inputs=['Softmax_374_input_cast_0'], outputs=['Softmax_374_output_cast_0'], name='Softmax_374', axis=2),
            make_node('Cast', inputs=['Softmax_374_output_cast_0'], outputs=['661'], name='Softmax_374_output_cast0', to=TensorProto.FLOAT16),
            make_node('Transpose', inputs=['661'], outputs=['graph_output_cast_0'], name='Transpose_375', perm=[0, 2, 1]),
            make_node('Cast', inputs=['graph_output_cast_0'], outputs=['output'], name='graph_output_cast0', to=TensorProto.FLOAT),
        ],
    ),
)

if __name__ == '__main__' and len(sys.argv) == 2:
    _, out_path = sys.argv
    onnx.save(model, out_path)
